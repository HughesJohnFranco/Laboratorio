import os
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from collections import Counter

# --- ConfiguraciÃ³n ---
RUTA_KEYPOINTS = 'C:/Users/alen_/repos/Laboratorio/data/keypoints'

X = []
y = []

# --- Cargar archivos ---
print("ğŸ“‚ Cargando secuencias desde:", RUTA_KEYPOINTS)
for archivo in os.listdir(RUTA_KEYPOINTS):
    if not archivo.endswith('.h5'):
        continue

    ruta_archivo = os.path.join(RUTA_KEYPOINTS, archivo)
    df = pd.read_hdf(ruta_archivo)

    if df.shape != (10, 225):  # âœ… Ajuste aquÃ­
        print(f"âŒ Formato invÃ¡lido: {archivo} -> {df.shape}")
        continue

    X.append(df.values)

    # Etiqueta: todo menos el "_muestraX.h5"
    etiqueta = '_'.join(archivo.split('_')[:-1])
    y.append(etiqueta)

print("âœ… Cargadas muestras:", len(X))

# --- Verificar clases ---
print("\nğŸ“Š DistribuciÃ³n de clases:")
conteo = Counter(y)
for clase, cantidad in conteo.items():
    print(f"  {clase}: {cantidad} muestras")

# --- Preparar datos ---
X = np.array(X)
y = np.array(y)

encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

print("\nğŸŒ¤ Clases codificadas:")
for clase, idx in zip(encoder.classes_, range(len(encoder.classes_))):
    print(f"  {clase}: {idx}")

# --- Dividir en entrenamiento y testeo ---
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.33, random_state=42, stratify=y_encoded
)

print(f"\nğŸ“ Train: {len(X_train)} muestras | Test: {len(X_test)} muestras")

# --- Definir modelo ---
modelo = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(10, 225)),  # âœ… Ajuste aquÃ­ tambiÃ©n
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(len(encoder.classes_), activation='softmax')
])

modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# --- Entrenar ---
print("\nğŸš€ Entrenando modelo...")
hist = modelo.fit(X_train, y_train, epochs=250, batch_size=4, validation_data=(X_test, y_test))

# --- EvaluaciÃ³n ---
print("\nğŸ“ˆ Evaluando modelo...")
loss, acc = modelo.evaluate(X_test, y_test)
print(f"\nâœ… PrecisiÃ³n del modelo: {acc:.2f}")

# --- DiagnÃ³stico de predicciones ---
print("\nğŸ” DiagnÃ³stico de predicciones:")
predicciones = modelo.predict(X_test)
clases_predichas = np.argmax(predicciones, axis=1)

print("ğŸŸ¡ Clases verdaderas: ", y_test)
print("ğŸ”¹ Clases predichas:  ", clases_predichas)
print("ğŸŒ¤ Etiquetas reales:  ", encoder.inverse_transform(y_test))
print("ğŸŒ¤ Etiquetas predichas:", encoder.inverse_transform(clases_predichas))

# --- Guardar modelo ---
modelo.save('modelo_secuencial_lsa.keras')
print("\nğŸ“‚ Modelo guardado como 'modelo_secuencial_lsa.keras'")
